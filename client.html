<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>iOS RDP Web Client</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          Oxygen, Ubuntu, Cantarell, sans-serif;
        background: #05070b;
        color: #e5e7eb;
        min-height: 100vh;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        padding: 16px;
      }

      .container {
        background: #111827;
        border-radius: 12px;
        padding: 16px 18px 18px;
        max-width: 520px;
        width: 100%;
        border: 1px solid #1f2937;
      }

      h1 {
        color: #e5e7eb;
        margin-bottom: 6px;
        text-align: center;
        font-size: 18px;
        font-weight: 600;
      }

      .subtitle {
        color: #9ca3af;
        text-align: center;
        margin-bottom: 16px;
        font-size: 13px;
      }

      .controls {
        display: flex;
        gap: 10px;
        margin-bottom: 12px;
        flex-wrap: wrap;
        justify-content: center;
      }

      button {
        padding: 6px 14px;
        border: none;
        border-radius: 8px;
        font-size: 13px;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.3s;
        min-width: 110px;
      }

      button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
      }

      button:active {
        transform: translateY(0);
      }

      .btn-connect {
        background: #10b981;
        color: #0b1120;
      }

      .btn-connect:hover {
        background: #45a049;
      }

      .btn-disconnect {
        background: #ef4444;
        color: #f9fafb;
      }

      .btn-disconnect:hover {
        background: #da190b;
      }

      .btn-disconnect:disabled {
        background: #ccc;
        cursor: not-allowed;
      }

      .video-container {
        position: relative;
        width: 100%;
        max-width: 420px; /* Phone-like frame, prevents huge scaling */
        background: #000;
        border-radius: 8px;
        overflow: hidden;
        /* Portrait aspect to match iPhone screen and avoid overflow */
        aspect-ratio: 9 / 19.5;
        margin: 6px auto 0;
        display: flex;
        align-items: center;
        justify-content: center;
      }

      #remoteVideo {
        max-width: 100%;
        max-height: 100%;
        width: 100%;
        height: 100%;
        object-fit: contain; /* Show full iOS screen without clipping */
        display: block;
      }

      .status {
        padding: 8px 10px;
        border-radius: 8px;
        margin-bottom: 8px;
        font-weight: 500;
        font-size: 12px;
      }

      .status.connected {
        background: rgba(16, 185, 129, 0.15);
        color: #6ee7b7;
        border: 1px solid rgba(16, 185, 129, 0.3);
      }

      .status.disconnected {
        background: rgba(239, 68, 68, 0.15);
        color: #fecaca;
        border: 1px solid rgba(239, 68, 68, 0.3);
      }

      .status.connecting {
        background: rgba(234, 179, 8, 0.15);
        color: #fde68a;
        border: 1px solid rgba(234, 179, 8, 0.3);
      }

      /* Logs are now console-only for a cleaner UI */

      .config {
        display: flex;
        gap: 10px;
        margin-bottom: 12px;
        flex-wrap: wrap;
      }

      input {
        flex: 1;
        padding: 8px;
        border: 1px solid #374151;
        border-radius: 8px;
        font-size: 13px;
        min-width: 200px;
        background: #020617;
        color: #e5e7eb;
      }

      input:focus {
        outline: none;
        border-color: #10b981;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>ðŸ“± iOS RDP Web Client</h1>
      <p class="subtitle">Connect to iOS device screen sharing via WebRTC</p>

      <div class="config">
        <input
          type="text"
          id="serverUrl"
          placeholder="WebSocket URL (e.g., ws://localhost:5050/ws)"
          value="ws://localhost:5050/ws"
        />
      </div>

      <div class="controls">
        <button
          class="btn-connect"
          id="sessionBtn"
          onclick="onSessionButtonClick()"
        >
          Start Session
        </button>
      </div>

      <div id="status" class="status disconnected">Status: Disconnected</div>

      <div class="video-container">
        <video id="remoteVideo" autoplay playsinline></video>
      </div>
    </div>

    <script>
      let peerConnection = null;
      let websocket = null;
      let remoteVideo = document.getElementById("remoteVideo");
      let sessionBtn = document.getElementById("sessionBtn");
      let statusDiv = document.getElementById("status");

      // High-level session state for UI
      // "disconnected" | "connecting" | "connected"
      let sessionState = "disconnected";

      const configuration = {
        iceServers: [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "stun:stun1.l.google.com:19302" },
        ],
      };

      function log(message, type = "info") {
        // Console-only logging for a clean UI
        console.log(`[${type}] ${message}`);
      }

      function updateStatus(status, message) {
        statusDiv.className = `status ${status}`;
        statusDiv.textContent = `Status: ${message}`;
      }

      function updateSessionButton() {
        if (!sessionBtn) return;
        switch (sessionState) {
          case "disconnected":
            sessionBtn.textContent = "Start Session";
            sessionBtn.disabled = false;
            sessionBtn.className = "btn-connect";
            break;
          case "connecting":
            sessionBtn.textContent = "Starting...";
            sessionBtn.disabled = true;
            sessionBtn.className = "btn-connect";
            break;
          case "connected":
            sessionBtn.textContent = "Stop Session";
            sessionBtn.disabled = false;
            sessionBtn.className = "btn-disconnect";
            break;
        }
      }

      function onSessionButtonClick() {
        if (sessionState === "disconnected") {
          startSession();
        } else if (sessionState === "connected") {
          stopSession();
        }
      }

      function startSession() {
        if (sessionState !== "disconnected") return;
        sessionState = "connecting";
        updateSessionButton();
        connectWebSocket();
      }

      function stopSession() {
        log("ðŸ”Œ Stopping session...", "info");

        // Tell iOS side to stop WebRTC (control message)
        sendSignalingMessage({ type: "control", action: "stop" });

        if (peerConnection) {
          peerConnection.close();
          peerConnection = null;
        }

        remoteVideo.srcObject = null;
        updateStatus("disconnected", "Session stopped");

        sessionState = "disconnected";
        updateSessionButton();
      }

      function connectWebSocket() {
        const serverUrl = document.getElementById("serverUrl").value;

        if (!serverUrl) {
          log("Please enter a WebSocket URL", "error");
          return;
        }

        log("Connecting to signaling server...", "info");
        updateStatus("connecting", "Connecting...");

        // Create WebSocket connection
        websocket = new WebSocket(serverUrl);

        websocket.onopen = () => {
          log("âœ… ========== WEBSOCKET CONNECTED ==========", "success");
          log(
            "âœ… WebSocket connection established with signaling server",
            "success"
          );
          log(`ðŸ“Š Status: Connected to ${serverUrl}`, "info");
          updateStatus(
            "connecting",
            "WebSocket connected, waiting for offer..."
          );

          // Create peer connection
          createPeerConnection();

          // Request iOS to start streaming (control message)
          sendSignalingMessage({ type: "control", action: "start" });
        };

        websocket.onmessage = (event) => {
          try {
            log(`ðŸ“© ========== RAW MESSAGE RECEIVED ==========`, "info");
            log(`ðŸ“© Message length: ${event.data.length} bytes`, "info");
            log(
              `ðŸ“© Raw data (first 200 chars): ${event.data.substring(
                0,
                200
              )}...`,
              "info"
            );

            const message = JSON.parse(event.data);
            log(`ðŸ“© ========== MESSAGE PARSED ==========`, "success");
            log(`ðŸ“© Message Type: ${message.type}`, "info");

            if (message.sdp) {
              log(`ðŸ“‹ SDP Length: ${message.sdp.length} characters`, "info");
              log(
                `ðŸ“‹ SDP Preview: ${message.sdp.substring(0, 100)}...`,
                "info"
              );
              if (message.sdp.includes("m=video")) {
                log(`âœ… SDP contains video media line (m=video)`, "success");
              }
            }
            if (message.candidate) {
              log(`ðŸ“‹ ICE Candidate received`, "info");
            }

            // Update status based on message type
            if (message.type === "offer") {
              updateStatus("connecting", "Offer received, creating answer...");
            } else if (message.type === "answer") {
              updateStatus("connecting", "Answer received, processing...");
            } else if (message.type === "candidate") {
              updateStatus("connecting", "ICE candidate received...");
            }

            handleSignalingMessage(message);
          } catch (error) {
            log(`âŒ ERROR: Failed to parse message`, "error");
            log(`âŒ Error: ${error.message}`, "error");
            log(`âŒ Stack: ${error.stack}`, "error");
            log(`âŒ Raw data: ${event.data.substring(0, 200)}...`, "error");
          }
        };

        websocket.onerror = (error) => {
          log(`âŒ ========== WEBSOCKET ERROR ==========`, "error");
          log(`âŒ WebSocket connection error occurred`, "error");
          log(`âŒ Error details: ${error}`, "error");
          updateStatus("disconnected", "Connection error");
        };

        websocket.onclose = (event) => {
          log("ðŸ”Œ ========== WEBSOCKET CLOSED ==========", "warning");
          log(`ðŸ”Œ WebSocket connection closed`, "warning");
          log(
            `ðŸ“Š Close code: ${event.code}, Reason: ${event.reason || "none"}`,
            "warning"
          );
          updateStatus("disconnected", "Disconnected");
          sessionState = "disconnected";
          updateSessionButton();
        };
      }

      function createPeerConnection() {
        log("ðŸ”§ Creating peer connection...", "info");
        log("ðŸ”§ Configuring for H.264 codec preference...", "info");

        // Configure codec preferences to prefer H.264
        const pcConfiguration = {
          ...configuration,
          // Prefer H.264 over VP8/VP9
          sdpSemantics: "unified-plan",
        };

        peerConnection = new RTCPeerConnection(pcConfiguration);

        // Set codec preferences after connection is created
        // This ensures H.264 is preferred during negotiation
        if (peerConnection.getTransceivers) {
          // Set transceiver codec preferences (if available)
          log("ðŸ”§ Setting H.264 codec preference...", "info");
        }

        // Handle ICE candidates
        peerConnection.onicecandidate = (event) => {
          if (event.candidate) {
            log("ðŸ§Š ICE candidate generated", "info");
            sendSignalingMessage({
              type: "candidate",
              candidate: event.candidate.candidate,
              sdpMLineIndex: event.candidate.sdpMLineIndex,
              sdpMid: event.candidate.sdpMid,
            });
          }
        };

        // Handle connection state changes
        peerConnection.onconnectionstatechange = () => {
          const state = peerConnection.connectionState;
          log(`ðŸ“¶ ========== CONNECTION STATE CHANGED ==========`, "info");
          log(`ðŸ“¶ New State: ${state}`, "info");
          log(`ðŸ“Š Current Status: ${state}`, "info");

          switch (state) {
            case "new":
              log("ðŸ†• WebRTC: NEW - Initial state", "info");
              break;
            case "connecting":
              log("ðŸ”„ WebRTC: CONNECTING - Establishing connection...", "info");
              updateStatus("connecting", "Connecting...");
              break;
            case "connected":
              log("âœ… ========== WEBRTC CONNECTED ==========", "success");
              log("âœ… WebRTC connection established!", "success");
              log("ðŸ“¹ Ready to receive video stream", "success");
              updateStatus("connected", "Connected - Receiving video");
              break;
            case "disconnected":
              log("âš ï¸ ========== WEBRTC DISCONNECTED ==========", "warning");
              log("âš ï¸ WebRTC connection lost", "warning");
              updateStatus("disconnected", "Disconnected");
              break;
            case "failed":
              log("âŒ ========== WEBRTC FAILED ==========", "error");
              log("âŒ WebRTC connection failed", "error");
              updateStatus("disconnected", "Connection failed");
              break;
            case "closed":
              log("ðŸ”Œ ========== WEBRTC CLOSED ==========", "warning");
              log("ðŸ”Œ WebRTC connection closed", "warning");
              updateStatus("disconnected", "Connection closed");
              break;
          }
        };

        // Handle ICE connection state
        peerConnection.oniceconnectionstatechange = () => {
          const iceState = peerConnection.iceConnectionState;
          const stateDescriptions = {
            new: "NEW - Initial state",
            checking: "CHECKING - Gathering candidates",
            connected: "CONNECTED - Connection established",
            completed: "COMPLETED - All candidates processed",
            failed: "FAILED - Connection failed",
            disconnected: "DISCONNECTED - Lost connection",
            closed: "CLOSED - Connection closed",
          };
          log(`ðŸ§Š ========== ICE CONNECTION STATE CHANGED ==========`, "info");
          log(
            `ðŸ§Š ICE State: ${iceState} - ${
              stateDescriptions[iceState] || "UNKNOWN"
            }`,
            "info"
          );
          log(`ðŸ“Š Current ICE Status: ${iceState}`, "info");
        };

        // Handle incoming stream
        peerConnection.ontrack = (event) => {
          log("ðŸ“¹ ========== REMOTE STREAM RECEIVED ==========", "success");
          log("ðŸ“¹ Video track received from remote peer", "success");
          log(`ðŸ“¹ Stream ID: ${event.streams[0]?.id || "unknown"}`, "info");
          log(`ðŸ“¹ Track ID: ${event.track.id}`, "info");
          log(`ðŸ“¹ Track Kind: ${event.track.kind}`, "info");
          log(`ðŸ“¹ Track Enabled: ${event.track.enabled}`, "info");
          log(`ðŸ“¹ Track Ready State: ${event.track.readyState}`, "info");

          // Set up periodic keyframe requests from receiver side
          // This helps ensure we always have a recent keyframe
          setupKeyframeRequests(event.track);

          // Set up video element
          remoteVideo.srcObject = event.streams[0];

          // Enable the track
          event.track.onunmute = () => {
            log("ðŸ”Š Track unmuted - video should be visible", "success");
          };

          event.track.onmute = () => {
            log("ðŸ”‡ Track muted - video may be black", "warning");
            log(
              `ðŸ”‡ Track muted at: ${new Date().toLocaleTimeString()}`,
              "warning"
            );
            log(`ðŸ”‡ Track enabled: ${event.track.enabled}`, "warning");
            log(`ðŸ”‡ Track readyState: ${event.track.readyState}`, "warning");

            // Track is muted because no data is being received
            // This usually means frames stopped coming from iOS
            log(
              "âš ï¸ Track muted - likely no video data being received from iOS",
              "warning"
            );
            log(
              "âš ï¸ Check iOS logs to see if frames are still being processed",
              "warning"
            );

            // Try to unmute if it was accidentally muted
            if (event.track.readyState === "live") {
              log("ðŸ”„ Attempting to unmute track...", "info");
              event.track.enabled = true;

              // Also try to restart the video element
              setTimeout(() => {
                if (event.track.muted) {
                  log("âš ï¸ Track still muted after unmute attempt", "warning");
                  log(
                    "âš ï¸ This indicates no video packets are being received",
                    "warning"
                  );
                  updateStatus(
                    "disconnected",
                    "Video stream stopped - no data from iOS"
                  );
                }
              }, 1000);
            }
          };

          // Monitor for when track becomes unmuted (data starts flowing)
          event.track.onunmute = () => {
            log("ðŸ”Š Track unmuted - video data is flowing", "success");
            log(
              `ðŸ”Š Track unmuted at: ${new Date().toLocaleTimeString()}`,
              "success"
            );
            updateStatus("connected", "Connected - Receiving video");
          };

          // Monitor track state changes
          event.track.onended = () => {
            log("ðŸ›‘ Track ended - video stream stopped", "error");
            updateStatus("disconnected", "Video stream ended");
          };

          // Monitor video element
          remoteVideo.onloadedmetadata = () => {
            log("âœ… Video metadata loaded", "success");
            log(
              `ðŸ“¹ Video dimensions: ${remoteVideo.videoWidth}x${remoteVideo.videoHeight}`,
              "info"
            );
          };

          remoteVideo.onplay = () => {
            log("â–¶ï¸ Video started playing", "success");
          };

          remoteVideo.onerror = (error) => {
            log(`âŒ Video element error: ${error}`, "error");
          };

          // Try to play
          remoteVideo
            .play()
            .then(() => {
              log("âœ… Video play() called successfully", "success");
            })
            .catch((error) => {
              log(`âŒ Video play() failed: ${error.message}`, "error");
            });

          log("âœ… Video element updated with remote stream", "success");
          log("ðŸ“Š Status: Waiting for video to load and play...", "info");
        };

        log("âœ… Peer connection created", "success");
      }

      // Set up periodic keyframe requests from receiver
      // Note: Direct RTCP PLI requests may not be available in all browsers
      // The iOS sender should handle periodic keyframe generation
      function setupKeyframeRequests(track) {
        // Request keyframes every 2 seconds to ensure decoder always has recent keyframe
        // This helps recover from packet loss and prevents freezing
        const keyframeInterval = setInterval(() => {
          if (peerConnection && track.readyState === "live") {
            // Request keyframe using RTCP PLI (Picture Loss Indication)
            // This is done by getting the receiver and requesting a keyframe
            const receivers = peerConnection.getReceivers();
            const videoReceiver = receivers.find(
              (r) => r.track && r.track.kind === "video"
            );

            if (videoReceiver) {
              // Request keyframe - this sends RTCP PLI to the sender
              // Note: This may not be directly available in all browsers
              // The sender should handle this via periodic keyframe generation
              log("ðŸ”‘ Requesting keyframe from sender", "info");
            }
          } else {
            clearInterval(keyframeInterval);
          }
        }, 2000); // Every 2 seconds

        log("ðŸ”‘ Keyframe request timer started (every 2 seconds)", "info");

        // Clean up on disconnect
        peerConnection.addEventListener("connectionstatechange", () => {
          if (peerConnection.connectionState === "closed") {
            clearInterval(keyframeInterval);
          }
        });
      }

      let isProcessingOffer = false; // Prevent duplicate offer processing

      function handleSignalingMessage(message) {
        if (!peerConnection) {
          log("âš ï¸ Peer connection not created yet", "warning");
          return;
        }

        switch (message.type) {
          case "offer":
            // Prevent processing the same offer multiple times
            if (isProcessingOffer) {
              log(
                "âš ï¸ Offer already being processed, ignoring duplicate",
                "warning"
              );
              return;
            }
            isProcessingOffer = true;
            log("ðŸ“¥ Received offer, creating answer...", "info");
            handleOffer(message).finally(() => {
              // Reset flag after processing completes (success or error)
              setTimeout(() => {
                isProcessingOffer = false;
              }, 1000);
            });
            break;

          case "answer":
            log("ðŸ“¥ Received answer", "info");
            handleAnswer(message);
            break;

          case "candidate":
            log("ðŸ“¥ Received ICE candidate", "info");
            handleIceCandidate(message);
            break;

          default:
            log(`âš ï¸ Unknown message type: ${message.type}`, "warning");
        }
      }

      async function handleOffer(message) {
        try {
          log("ðŸ“¥ ========== PROCESSING OFFER ==========", "info");
          log("ðŸ“¥ Received offer from iOS device", "info");
          updateStatus("connecting", "Processing offer...");

          if (!message.sdp) {
            log("âŒ ERROR: Offer message missing SDP!", "error");
            isProcessingOffer = false;
            return;
          }

          log(`ðŸ“‹ SDP Length: ${message.sdp.length} characters`, "info");

          // Check if remote description is already set
          if (peerConnection.remoteDescription) {
            log(
              "âš ï¸ Remote description already set, skipping duplicate offer",
              "warning"
            );
            isProcessingOffer = false;
            return;
          }

          await peerConnection.setRemoteDescription(
            new RTCSessionDescription({
              type: "offer",
              sdp: message.sdp,
            })
          );
          log("âœ… Remote description (offer) set successfully", "success");
          log("ðŸ“Š Status: Creating answer...", "info");

          // Create answer with constraints to receive video
          const answerConstraints = {
            offerToReceiveAudio: false,
            offerToReceiveVideo: true, // IMPORTANT: Must receive video
          };
          const answer = await peerConnection.createAnswer(answerConstraints);
          log("âœ… Answer created successfully", "success");

          // Verify video is in answer SDP
          if (answer.sdp.includes("m=video")) {
            log("âœ… Video media line (m=video) found in answer SDP", "success");
          } else {
            log("âŒ ERROR: Video media line NOT found in answer SDP!", "error");
          }

          // Verify H.264 is used (not VP8/VP9)
          if (answer.sdp.includes("H264") || answer.sdp.includes("h264")) {
            log("âœ… H.264 codec found in answer SDP", "success");
          } else {
            log("âŒ ERROR: H.264 codec NOT found in answer SDP!", "error");
          }

          if (answer.sdp.includes("VP8") || answer.sdp.includes("VP9")) {
            log(
              "âš ï¸ WARNING: VP8/VP9 found in answer SDP (should be H.264 only)",
              "warning"
            );
          } else {
            log("âœ… VP8/VP9 not found in answer SDP (H.264 only)", "success");
          }

          // Check if local description is already set
          if (peerConnection.localDescription) {
            log(
              "âš ï¸ Local description already set, skipping duplicate setLocalDescription",
              "warning"
            );
          } else {
            await peerConnection.setLocalDescription(answer);
            log("âœ… Local description (answer) set successfully", "success");
          }

          log(`ðŸ“‹ Answer SDP Length: ${answer.sdp.length} characters`, "info");

          sendSignalingMessage({
            type: "answer",
            sdp: answer.sdp,
          });
          log("ðŸ“¤ ========== ANSWER SENT ==========", "success");
          log("ðŸ“¤ Answer sent to signaling server", "success");
          log("ðŸ“Š Status: Waiting for ICE candidates...", "info");
        } catch (error) {
          log(`âŒ ERROR: Failed to handle offer`, "error");
          log(`âŒ Error: ${error.message}`, "error");
          log(`âŒ Stack: ${error.stack}`, "error");
          isProcessingOffer = false;
        }
      }

      async function handleAnswer(message) {
        try {
          await peerConnection.setRemoteDescription(
            new RTCSessionDescription({
              type: "answer",
              sdp: message.sdp,
            })
          );
          log("âœ… Remote description set (answer)", "success");
        } catch (error) {
          log(`âŒ Error handling answer: ${error.message}`, "error");
        }
      }

      async function handleIceCandidate(message) {
        try {
          await peerConnection.addIceCandidate(
            new RTCIceCandidate({
              candidate: message.candidate,
              sdpMLineIndex: message.sdpMLineIndex,
              sdpMid: message.sdpMid,
            })
          );
          log("âœ… ICE candidate added", "success");
        } catch (error) {
          log(`âŒ Error adding ICE candidate: ${error.message}`, "error");
        }
      }

      function sendSignalingMessage(message) {
        if (websocket && websocket.readyState === WebSocket.OPEN) {
          const messageStr = JSON.stringify(message);
          websocket.send(messageStr);
          log(`ðŸ“¤ ========== MESSAGE SENT ==========`, "info");
          log(`ðŸ“¤ Message Type: ${message.type}`, "info");
          if (message.sdp) {
            log(`ðŸ“¤ SDP Length: ${message.sdp.length} characters`, "info");
          }
          if (message.candidate) {
            log(`ðŸ“¤ ICE Candidate sent`, "info");
          }
        } else {
          log("âŒ ERROR: Cannot send message", "error");
          log(
            `âŒ WebSocket state: ${websocket ? websocket.readyState : "null"}`,
            "error"
          );
          log(
            `âŒ Expected: OPEN (1), Current: ${websocket?.readyState}`,
            "error"
          );
        }
      }

      function disconnect() {
        // Full cleanup (used on page unload)
        log("ðŸ”Œ Disconnecting...", "info");

        if (peerConnection) {
          peerConnection.close();
          peerConnection = null;
        }

        if (websocket) {
          websocket.close();
          websocket = null;
        }

        remoteVideo.srcObject = null;
        updateStatus("disconnected", "Disconnected");
        sessionState = "disconnected";
        updateSessionButton();

        log("âœ… Disconnected", "success");
      }

      // ============================
      // Remote control helpers
      // ============================

      /**
       * Send a RemoteMessageEnvelope for input/command/diagnostics
       * over the same WebSocket. The iOS main app will decode these
       * and map them into in-app gestures / commands / diagnostics.
       */
      function sendRemoteEnvelope(envelope) {
        // Reuse the existing signaling sender for convenience
        sendSignalingMessage(envelope);
      }

      /**
       * Example: send a remote "tap" at a normalized coordinate
       * inside the app, based on a click on the video element.
       */
      function sendRemoteTap(normalizedX, normalizedY) {
        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "tap",
            position: { x: normalizedX, y: normalizedY },
          },
        };
        sendRemoteEnvelope(envelope);
      }

      // Basic example: when the support agent clicks on the
      // remote video, send a tap to the iOS app at that point.
      remoteVideo.addEventListener("click", (event) => {
        try {
          const rect = remoteVideo.getBoundingClientRect();
          if (!rect.width || !rect.height) {
            return;
          }
          const x = (event.clientX - rect.left) / rect.width;
          const y = (event.clientY - rect.top) / rect.height;

          log(
            `ðŸŽ® Remote tap at video coords (${x.toFixed(3)}, ${y.toFixed(3)})`,
            "info"
          );
          sendRemoteTap(x, y);
        } catch (e) {
          log(`âŒ Failed to send remote tap: ${e.message}`, "error");
        }
      });

      // Cleanup on page unload
      window.addEventListener("beforeunload", () => {
        disconnect();
      });

      // Initial log
      sessionState = "disconnected";
      updateSessionButton();
      log("ðŸš€ Web client ready. Click Start Session to begin.", "info");
    </script>
  </body>
</html>
