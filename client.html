<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />
    <title>ZeroTouch iOS RDP</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      html,
      body {
        width: 100%;
        height: 100%;
        overflow-x: hidden;
        position: relative;
      }

      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          Oxygen, Ubuntu, Cantarell, sans-serif;
        background: #000000;
        color: #e5e7eb;
        min-height: 100vh;
        display: flex;
        flex-direction: row;
        align-items: center;
        justify-content: center;
        padding: 20px;
        gap: 20px;
        overflow-x: auto; /* Prevent horizontal scroll issues */
        box-sizing: border-box;
      }

      html {
        overflow-x: hidden;
        box-sizing: border-box;
      }

      @media (max-width: 900px) {
        body {
          flex-direction: column;
          padding: 16px;
        }
        .container {
          flex-direction: column;
          max-width: 100%;
        }
        .simulator-left {
          width: 100%;
        }
        .simulator-right {
          width: 100%;
        }
      }

      .container {
        background: #000000;
        border-radius: 12px;
        padding: 16px;
        display: flex;
        flex-direction: row;
        gap: 20px;
        max-width: 1200px;
        width: 100%;
        min-width: 0; /* Prevent flex shrinking issues */
        border: 1px solid rgba(255, 255, 255, 0.1);
        transition: border-color 0.3s ease;
        box-sizing: border-box;
      }

      .container:hover {
        border-color: rgba(255, 255, 255, 0.15);
      }

      .simulator-left {
        flex: 0 0 auto;
        display: flex;
        flex-direction: column;
        align-items: center;
        min-width: 0; /* Prevent flex shrinking */
        width: auto;
      }

      .simulator-right {
        flex: 1;
        display: flex;
        flex-direction: column;
        min-width: 300px;
        box-sizing: border-box;
      }

      h1 {
        color: #e5e7eb;
        margin-bottom: 12px;
        text-align: left;
        font-size: 18px;
        font-weight: 600;
        opacity: 0.9;
      }

      .subtitle {
        color: #9ca3af;
        text-align: center;
        margin-bottom: 16px;
        font-size: 13px;
      }

      .controls {
        display: flex;
        gap: 10px;
        margin-bottom: 12px;
        flex-wrap: wrap;
        justify-content: center;
      }

      button {
        padding: 6px 14px;
        border: none;
        border-radius: 8px;
        font-size: 13px;
        font-weight: 500;
        cursor: pointer;
        transition: all 0.3s;
        min-width: 110px;
      }

      button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
      }

      button:active {
        transform: translateY(0);
      }

      .btn-connect {
        background: #10b981;
        color: #0b1120;
      }

      .btn-connect:hover {
        background: #45a049;
      }

      .btn-disconnect {
        background: #ef4444;
        color: #f9fafb;
      }

      .btn-disconnect:hover {
        background: #da190b;
      }

      .btn-disconnect:disabled {
        background: #ccc;
        cursor: not-allowed;
      }

      .video-container {
        position: relative;
        width: 100%;
        max-width: 350px;
        min-width: 280px; /* Prevent shrinking below this */
        background: rgba(0, 0, 0, 0.8);
        border-radius: 24px;
        overflow: hidden;
        /* Portrait aspect to match iPhone screen */
        aspect-ratio: 9 / 19.5;
        padding: 8px;
        box-shadow: 0 0 30px rgba(0, 0, 0, 0.8), 0 0 60px rgba(0, 0, 0, 0.5),
          inset 0 0 20px rgba(255, 255, 255, 0.05);
        border: 2px solid rgba(255, 255, 255, 0.1);
        box-sizing: border-box;
        /* Prevent layout shifts */
        contain: layout style paint;
      }

      .video-container::before {
        content: "";
        position: absolute;
        top: 0;
        left: 50%;
        transform: translateX(-50%);
        width: 120px;
        height: 20px;
        background: #000;
        border-radius: 0 0 12px 12px;
        z-index: 5;
      }

      .play-overlay {
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        background: rgba(0, 0, 0, 0.8);
        display: flex;
        align-items: center;
        justify-content: center;
        flex-direction: column;
        gap: 12px;
        z-index: 10;
        cursor: pointer;
        border-radius: 8px;
        opacity: 0;
        pointer-events: none;
        transition: opacity 0.3s;
      }

      .play-overlay.visible {
        opacity: 1;
        pointer-events: all;
      }

      .play-overlay-icon {
        width: 64px;
        height: 64px;
        background: rgba(16, 185, 129, 0.9);
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 28px;
        color: #0b1120;
      }

      .play-overlay-text {
        color: #e5e7eb;
        font-size: 14px;
        font-weight: 500;
        text-align: center;
        padding: 0 20px;
      }

      #remoteVideo {
        width: 100%;
        height: 100%;
        object-fit: contain;
        display: block;
        background-color: rgba(0, 0, 0, 0.8);
        background: rgba(0, 0, 0, 0.8);
        border-radius: 16px;
      }

      .status {
        padding: 8px 12px;
        border-radius: 6px;
        margin-bottom: 16px;
        font-weight: 500;
        font-size: 12px;
        text-align: left;
        opacity: 0.9;
        transition: opacity 0.3s ease;
      }

      .status:hover {
        opacity: 1;
      }

      .status.connected {
        background: rgba(16, 185, 129, 0.15);
        color: #6ee7b7;
        border: 1px solid rgba(16, 185, 129, 0.3);
      }

      .status.disconnected {
        background: rgba(239, 68, 68, 0.15);
        color: #fecaca;
        border: 1px solid rgba(239, 68, 68, 0.3);
      }

      .status.connecting {
        background: rgba(234, 179, 8, 0.15);
        color: #fde68a;
        border: 1px solid rgba(234, 179, 8, 0.3);
      }

      .input-status {
        margin-top: 6px;
        font-size: 11px;
        color: #9ca3af;
        text-align: center;
        display: none; /* Hidden by default */
      }

      .keyboard-panel {
        margin-top: 0;
        padding-top: 0;
        display: flex;
        flex-direction: column;
        gap: 12px;
      }

      .panel-label {
        font-size: 11px;
        font-weight: 600;
        color: rgba(255, 255, 255, 0.6);
        text-transform: uppercase;
        letter-spacing: 0.5px;
        margin-bottom: 4px;
      }

      .keyboard-row {
        display: flex;
        gap: 10px;
        justify-content: flex-start;
        align-items: flex-start;
        flex-wrap: wrap;
        padding-bottom: 20px;
      }

      .nav-panel {
        margin-top: 16px;
        padding-top: 16px;
        border-top: 1px solid rgba(255, 255, 255, 0.1);
        display: flex;
        flex-direction: column;
        gap: 12px;
      }

      .nav-row {
        display: flex;
        gap: 10px;
        justify-content: flex-start;
        align-items: flex-start;
        flex-wrap: wrap;
        padding-bottom: 20px;
      }

      .keyboard-input {
        flex: 1;
        padding: 10px 12px;
        border-radius: 6px;
        border: 1px solid rgba(255, 255, 255, 0.1);
        background: rgba(255, 255, 255, 0.05);
        color: #e5e7eb;
        font-size: 13px;
        transition: all 0.2s ease;
        height: 40px;
        box-sizing: border-box;
      }

      .keyboard-input:focus {
        outline: none;
        border-color: rgba(16, 185, 129, 0.5);
        background: rgba(255, 255, 255, 0.08);
      }

      .keyboard-input::placeholder {
        color: rgba(255, 255, 255, 0.4);
      }

      .keyboard-key-btn {
        padding: 0;
        border-radius: 8px;
        border: 1px solid rgba(255, 255, 255, 0.1);
        background: rgba(255, 255, 255, 0.05);
        color: #e5e7eb;
        min-width: 44px;
        width: 44px;
        height: 44px;
        flex: 0 0 auto;
        cursor: pointer;
        transition: all 0.2s ease;
        display: flex;
        align-items: center;
        justify-content: center;
        box-sizing: border-box;
        position: relative;
        overflow: visible;
      }

      .keyboard-key-btn svg {
        width: 20px;
        height: 20px;
        stroke: currentColor;
        fill: none;
        stroke-width: 2;
        stroke-linecap: round;
        stroke-linejoin: round;
      }

      .keyboard-key-btn[data-label]::after {
        content: attr(data-label);
        position: absolute;
        bottom: -20px;
        left: 50%;
        transform: translateX(-50%);
        font-size: 9px;
        color: rgba(255, 255, 255, 0.5);
        white-space: nowrap;
        pointer-events: none;
        font-weight: 400;
      }

      .keyboard-key-btn:hover {
        background: rgba(255, 255, 255, 0.1);
        border-color: rgba(255, 255, 255, 0.2);
        transform: translateY(-1px);
      }

      .keyboard-key-btn:active {
        transform: translateY(0);
        background: rgba(255, 255, 255, 0.15);
      }

      /* Logs are now console-only for a cleaner UI */

      .config {
        display: flex;
        gap: 10px;
        margin-bottom: 12px;
        flex-wrap: wrap;
      }

      input {
        flex: 1;
        padding: 8px;
        border: 1px solid #374151;
        border-radius: 8px;
        font-size: 13px;
        min-width: 200px;
        background: #000000;
        color: #e5e7eb;
      }

      input:focus {
        outline: none;
        border-color: #10b981;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="simulator-left">
        <div class="video-container">
          <video id="remoteVideo" autoplay playsinline muted></video>
          <div id="playOverlay" class="play-overlay">
            <div class="play-overlay-icon">‚ñ∂</div>
            <div class="play-overlay-text">Click to enable video playback</div>
          </div>
        </div>
      </div>

      <div class="simulator-right">
        <h1>ZeroTouch iOS RDP</h1>
        <div id="status" class="status disconnected">Status: Disconnected</div>

        <!-- Input status hidden for cleaner UI -->
        <div id="inputStatus" class="input-status" style="display: none">
          Last input: none
        </div>

        <div class="keyboard-panel">
          <div class="panel-label">Keyboard</div>
          <div class="keyboard-row">
            <input
              type="text"
              id="kbText"
              class="keyboard-input"
              placeholder="Type text to send to device..."
            />
            <button
              class="keyboard-key-btn"
              type="button"
              onclick="sendKeyboardTextFromInput()"
              data-label="Send"
              title="Send text"
            >
              <svg viewBox="0 0 24 24">
                <line x1="22" y1="2" x2="11" y2="13"></line>
                <polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
              </svg>
            </button>
          </div>
          <div class="keyboard-row">
            <button
              class="keyboard-key-btn"
              type="button"
              onclick="sendRemoteKeyboardKey('enter')"
              data-label="Enter"
              title="Enter key"
            >
              <svg viewBox="0 0 24 24">
                <path d="M9 10l-5 5 5 5"></path>
                <path d="M20 4v6a4 4 0 0 1-4 4H4"></path>
                <line x1="20" y1="4" x2="20" y2="10"></line>
              </svg>
            </button>
            <button
              class="keyboard-key-btn"
              type="button"
              onclick="sendRemoteKeyboardKey('backspace')"
              data-label="Backspace"
              title="Backspace key"
            >
              <svg viewBox="0 0 24 24">
                <path
                  d="M21 4H8l-7 8 7 8h13a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2z"
                ></path>
                <line x1="18" y1="9" x2="12" y2="15"></line>
                <line x1="12" y1="9" x2="18" y2="15"></line>
              </svg>
            </button>
            <button
              class="keyboard-key-btn"
              type="button"
              onclick="sendRemoteKeyboardKey('tab')"
              data-label="Tab"
              title="Tab key"
            >
              <svg viewBox="0 0 24 24">
                <path d="M3 12h18"></path>
                <path d="M9 6l-6 6 6 6"></path>
                <path d="M15 6l6 6-6 6"></path>
              </svg>
            </button>
          </div>
        </div>
        <div class="nav-panel">
          <div class="panel-label">Navigation</div>
          <div class="nav-row">
            <button
              class="keyboard-key-btn"
              type="button"
              onclick="sendPopScreen()"
              data-label="Pop Screen"
              title="Pop screen"
            >
              <svg viewBox="0 0 24 24">
                <line x1="19" y1="12" x2="5" y2="12"></line>
                <polyline points="12 19 5 12 12 5"></polyline>
              </svg>
            </button>
            <button
              class="keyboard-key-btn"
              type="button"
              onclick="sendPopToRoot()"
              data-label="Pop To Root"
              title="Pop to root"
            >
              <svg viewBox="0 0 24 24">
                <path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
                <polyline points="9 22 9 12 15 12 15 22"></polyline>
              </svg>
            </button>
          </div>
        </div>
      </div>
    </div>

    <script>
      let peerConnection = null;
      let websocket = null;
      let remoteVideo = document.getElementById("remoteVideo");
      let playOverlay = document.getElementById("playOverlay");
      let statusDiv = document.getElementById("status");
      let inputStatusDiv = document.getElementById("inputStatus");

      // High-level session state for UI
      // "disconnected" | "connecting" | "connected"
      let sessionState = "disconnected";

      // Click / press handling for tap, double-tap, long-press, and swipe on the video
      let pendingTapTimeout = null;
      let pendingTapPosition = null;
      let longPressTimer = null;
      let longPressStartTime = null;
      let longPressPosition = null;
      let suppressNextClickFromLongPress = false;
      let swipeStartPosition = null;
      let swipeStartTime = null;

      // WebRTC ICE servers (STUN only for now).
      let configuration = {
        iceServers: [
          { urls: "stun:stun.l.google.com:19302" },
          { urls: "stun:stun1.l.google.com:19302" },
        ],
      };

      function log(message, type = "info") {
        // Console-only logging for a clean UI
        console.log(`[${type}] ${message}`);
      }

      function updateStatus(status, message) {
        statusDiv.className = `status ${status}`;
        statusDiv.textContent = `Status: ${message}`;
      }

      function updateInputStatus(message) {
        if (inputStatusDiv) {
          inputStatusDiv.textContent = `Last input: ${message}`;
        }
      }

      // Removed updateSessionButton and onSessionButtonClick - no button needed
      function updateSessionButton() {
        // No-op: button removed
      }

      function startSession() {
        if (sessionState !== "disconnected") return;
        sessionState = "connecting";
        connectWebSocket();
      }

      function stopSession() {
        log("üîå Stopping session...", "info");

        // Tell iOS side to stop WebRTC (control message)
        sendSignalingMessage({ type: "control", action: "stop" });

        if (peerConnection) {
          peerConnection.close();
          peerConnection = null;
        }

        remoteVideo.srcObject = null;
        updateStatus("disconnected", "Session stopped");

        sessionState = "disconnected";
        updateSessionButton();
      }

      function connectWebSocket() {
        // Use hardcoded server URL
        const serverUrl = "ws://localhost:5050/ws";
        // Read roomId from URL parameter (?room= or ?roomId=), fallback to default
        const urlParams = new URLSearchParams(window.location.search);
        const roomId =
          urlParams.get("room")?.trim() ||
          urlParams.get("roomId")?.trim() ||
          "default";

        log("Connecting to signaling server...", "info");
        updateStatus("connecting", "Connecting...");

        // Append roomId query parameter for session isolation
        const wsUrl = new URL(serverUrl);
        if (!wsUrl.searchParams.get("roomId")) {
          wsUrl.searchParams.set("roomId", roomId);
        }

        // Create WebSocket connection
        websocket = new WebSocket(wsUrl.toString());

        websocket.onopen = async () => {
          log("‚úÖ ========== WEBSOCKET CONNECTED ==========", "success");
          log(
            "‚úÖ WebSocket connection established with signaling server",
            "success"
          );
          log(`üìä Status: Connected to ${wsUrl.toString()}`, "info");
          updateStatus(
            "connecting",
            "WebSocket connected, waiting for offer..."
          );

          log("üßä ICE source: STUN (no TURN)", "info");

          // Create peer connection
          createPeerConnection();

          // Identify this connection to the signaling server for strict 1:1 routing
          sendSignalingMessage({ type: "hello", role: "web" });

          // Request iOS to start streaming (control message)
          sendSignalingMessage({ type: "control", action: "start" });
        };

        websocket.onmessage = (event) => {
          try {
            log(`üì© ========== RAW MESSAGE RECEIVED ==========`, "info");
            log(`üì© Message length: ${event.data.length} bytes`, "info");
            log(
              `üì© Raw data (first 200 chars): ${event.data.substring(
                0,
                200
              )}...`,
              "info"
            );

            const message = JSON.parse(event.data);
            log(`üì© ========== MESSAGE PARSED ==========`, "success");
            log(`üì© Message Type: ${message.type}`, "info");

            if (message.sdp) {
              log(`üìã SDP Length: ${message.sdp.length} characters`, "info");
              log(
                `üìã SDP Preview: ${message.sdp.substring(0, 100)}...`,
                "info"
              );
              if (message.sdp.includes("m=video")) {
                log(`‚úÖ SDP contains video media line (m=video)`, "success");
              }
            }
            if (message.candidate) {
              log(`üìã ICE Candidate received`, "info");
            }

            // Update status based on message type
            if (message.type === "offer") {
              updateStatus("connecting", "Offer received, creating answer...");
            } else if (message.type === "answer") {
              updateStatus("connecting", "Answer received, processing...");
            } else if (message.type === "candidate") {
              updateStatus("connecting", "ICE candidate received...");
            }

            handleSignalingMessage(message);
          } catch (error) {
            log(`‚ùå ERROR: Failed to parse message`, "error");
            log(`‚ùå Error: ${error.message}`, "error");
            log(`‚ùå Stack: ${error.stack}`, "error");
            log(`‚ùå Raw data: ${event.data.substring(0, 200)}...`, "error");
          }
        };

        websocket.onerror = (error) => {
          log(`‚ùå ========== WEBSOCKET ERROR ==========`, "error");
          log(`‚ùå WebSocket connection error occurred`, "error");
          log(`‚ùå Error details: ${error}`, "error");
          updateStatus("disconnected", "Connection error");
        };

        websocket.onclose = (event) => {
          log("üîå ========== WEBSOCKET CLOSED ==========", "warning");
          log(`üîå WebSocket connection closed`, "warning");
          log(
            `üìä Close code: ${event.code}, Reason: ${event.reason || "none"}`,
            "warning"
          );
          updateStatus("disconnected", "Disconnected");
          sessionState = "disconnected";
          updateSessionButton();
        };
      }

      function createPeerConnection() {
        log("üîß Creating peer connection...", "info");
        log("üîß Configuring for H.264 codec preference...", "info");

        // Configure codec preferences to prefer H.264
        const pcConfiguration = {
          ...configuration,
          // Prefer H.264 over VP8/VP9
          sdpSemantics: "unified-plan",
        };

        peerConnection = new RTCPeerConnection(pcConfiguration);

        // Set codec preferences after connection is created
        // This ensures H.264 is preferred during negotiation
        if (peerConnection.getTransceivers) {
          // Set transceiver codec preferences (if available)
          log("üîß Setting H.264 codec preference...", "info");
        }

        // Handle ICE candidates
        peerConnection.onicecandidate = (event) => {
          if (event.candidate) {
            log("üßä ICE candidate generated", "info");
            sendSignalingMessage({
              type: "candidate",
              candidate: event.candidate.candidate,
              sdpMLineIndex: event.candidate.sdpMLineIndex,
              sdpMid: event.candidate.sdpMid,
            });
          }
        };

        // Handle connection state changes
        peerConnection.onconnectionstatechange = () => {
          const state = peerConnection.connectionState;
          log(`üì∂ ========== CONNECTION STATE CHANGED ==========`, "info");
          log(`üì∂ New State: ${state}`, "info");
          log(`üìä Current Status: ${state}`, "info");

          switch (state) {
            case "new":
              log("üÜï WebRTC: NEW - Initial state", "info");
              break;
            case "connecting":
              log("üîÑ WebRTC: CONNECTING - Establishing connection...", "info");
              updateStatus("connecting", "Connecting...");
              break;
            case "connected":
              log("‚úÖ ========== WEBRTC CONNECTED ==========", "success");
              log("‚úÖ WebRTC connection established!", "success");
              log("üìπ Ready to receive video stream", "success");
              updateStatus("connected", "Connected - Receiving video");
              sessionState = "connected";
              updateSessionButton();
              break;
            case "disconnected":
              log("‚ö†Ô∏è ========== WEBRTC DISCONNECTED ==========", "warning");
              log("‚ö†Ô∏è WebRTC connection lost", "warning");
              updateStatus("disconnected", "Disconnected");
              sessionState = "disconnected";
              updateSessionButton();
              break;
            case "failed":
              log("‚ùå ========== WEBRTC FAILED ==========", "error");
              log("‚ùå WebRTC connection failed", "error");
              updateStatus("disconnected", "Connection failed");
              sessionState = "disconnected";
              updateSessionButton();
              break;
            case "closed":
              log("üîå ========== WEBRTC CLOSED ==========", "warning");
              log("üîå WebRTC connection closed", "warning");
              updateStatus("disconnected", "Connection closed");
              sessionState = "disconnected";
              updateSessionButton();
              break;
          }
        };

        // Handle ICE connection state
        peerConnection.oniceconnectionstatechange = () => {
          const iceState = peerConnection.iceConnectionState;
          const stateDescriptions = {
            new: "NEW - Initial state",
            checking: "CHECKING - Gathering candidates",
            connected: "CONNECTED - Connection established",
            completed: "COMPLETED - All candidates processed",
            failed: "FAILED - Connection failed",
            disconnected: "DISCONNECTED - Lost connection",
            closed: "CLOSED - Connection closed",
          };
          log(`üßä ========== ICE CONNECTION STATE CHANGED ==========`, "info");
          log(
            `üßä ICE State: ${iceState} - ${
              stateDescriptions[iceState] || "UNKNOWN"
            }`,
            "info"
          );
          log(`üìä Current ICE Status: ${iceState}`, "info");
        };

        // Handle incoming stream
        peerConnection.ontrack = (event) => {
          log("üìπ ========== REMOTE STREAM RECEIVED ==========", "success");
          log("üìπ Video track received from remote peer", "success");
          log(`üìπ Stream ID: ${event.streams[0]?.id || "unknown"}`, "info");
          log(`üìπ Track ID: ${event.track.id}`, "info");
          log(`üìπ Track Kind: ${event.track.kind}`, "info");
          log(`üìπ Track Enabled: ${event.track.enabled}`, "info");
          log(`üìπ Track Ready State: ${event.track.readyState}`, "info");
          log(`üìπ Track Muted: ${event.track.muted}`, "info");

          // CRITICAL: Explicitly enable the track
          if (event.track.kind === "video") {
            event.track.enabled = true;
            log("‚úÖ [TRACK] Video track explicitly enabled", "success");
          }

          // Set up periodic keyframe requests from receiver side
          // This helps ensure we always have a recent keyframe
          setupKeyframeRequests(event.track);

          // Set up video element
          remoteVideo.srcObject = event.streams[0];
          log(
            `‚úÖ [VIDEO] srcObject set with ${event.streams.length} stream(s)`,
            "success"
          );

          // Try playing while muted first (browsers allow muted autoplay more easily)
          // Then unmute after playback starts
          attemptVideoPlayMuted();

          // Enable the track
          event.track.onunmute = () => {
            log("üîä Track unmuted - video should be visible", "success");
          };

          event.track.onmute = () => {
            log("üîá Track muted - video may be black", "warning");
            log(
              `üîá Track muted at: ${new Date().toLocaleTimeString()}`,
              "warning"
            );
            log(`üîá Track enabled: ${event.track.enabled}`, "warning");
            log(`üîá Track readyState: ${event.track.readyState}`, "warning");

            // Track is muted because no data is being received
            // This usually means frames stopped coming from iOS
            log(
              "‚ö†Ô∏è Track muted - likely no video data being received from iOS",
              "warning"
            );
            log(
              "‚ö†Ô∏è Check iOS logs to see if frames are still being processed",
              "warning"
            );

            // Try to unmute if it was accidentally muted
            if (event.track.readyState === "live") {
              log("üîÑ Attempting to unmute track...", "info");
              event.track.enabled = true;

              // Also try to restart the video element
              setTimeout(() => {
                if (event.track.muted) {
                  log("‚ö†Ô∏è Track still muted after unmute attempt", "warning");
                  log(
                    "‚ö†Ô∏è This indicates no video packets are being received",
                    "warning"
                  );
                  updateStatus(
                    "disconnected",
                    "Video stream stopped - no data from iOS"
                  );
                }
              }, 1000);
            }
          };

          // Monitor for when track becomes unmuted (data starts flowing)
          event.track.onunmute = () => {
            log("üîä Track unmuted - video data is flowing", "success");
            log(
              `üîä Track unmuted at: ${new Date().toLocaleTimeString()}`,
              "success"
            );
            updateStatus("connected", "Connected - Receiving video");
          };

          // Monitor track state changes
          event.track.onended = () => {
            log("üõë Track ended - video stream stopped", "error");
            updateStatus("disconnected", "Video stream ended");
          };

          // Monitor video element
          remoteVideo.onloadedmetadata = () => {
            log("‚úÖ Video metadata loaded", "success");
            log(
              `üìπ Video dimensions: ${remoteVideo.videoWidth}x${remoteVideo.videoHeight}`,
              "info"
            );
            // Try to play when metadata loads
            attemptVideoPlay();
          };

          remoteVideo.onplay = () => {
            log("‚ñ∂Ô∏è Video started playing", "success");
            // Hide overlay immediately when video starts playing
            if (playOverlay) {
              playOverlay.classList.remove("visible");
              log("‚úÖ [OVERLAY] Hidden - video is playing", "success");
            }
          };

          // Also hide overlay when video has data (even if not playing yet)
          remoteVideo.addEventListener("loadeddata", () => {
            if (playOverlay && !remoteVideo.paused) {
              playOverlay.classList.remove("visible");
              log(
                "‚úÖ [OVERLAY] Hidden - video has data and is playing",
                "success"
              );
            }
          });

          // Show overlay only if video is paused (video playing = hide overlay)
          const checkPlayState = () => {
            // Hide overlay if video is playing (even if muted)
            if (playOverlay && !remoteVideo.paused) {
              playOverlay.classList.remove("visible");
            } else if (
              playOverlay &&
              remoteVideo.readyState >= 2 &&
              remoteVideo.paused &&
              videoPlayAttempts >= 5
            ) {
              // Only show overlay if video is paused AND all play attempts failed
              playOverlay.classList.add("visible");
            }
          };

          // Check play state periodically (less frequent)
          const playStateInterval = setInterval(() => {
            if (remoteVideo.srcObject) {
              checkPlayState();
            } else {
              clearInterval(playStateInterval);
            }
          }, 2000);

          // Also check on loadedmetadata
          remoteVideo.addEventListener("loadedmetadata", checkPlayState);

          remoteVideo.onerror = (error) => {
            log(`‚ùå Video element error: ${error}`, "error");
          };

          log("‚úÖ Video element updated with remote stream", "success");
          log("üìä Status: Waiting for video to load and play...", "info");

          // Start monitoring video statistics to check if packets are arriving
          startVideoStatisticsMonitoring(event.track);
        };

        log("‚úÖ Peer connection created", "success");
      }

      // Attempt to play video with multiple retries
      let videoPlayAttempts = 0;
      let isUnmuted = false;

      // First try playing muted (browsers allow this more easily)
      function attemptVideoPlayMuted() {
        if (!remoteVideo || !remoteVideo.srcObject) return;

        // Ensure video is muted for easier autoplay
        remoteVideo.muted = true;

        remoteVideo
          .play()
          .then(() => {
            log("‚úÖ Video play() succeeded (muted)", "success");
            videoPlayAttempts = 0;
            // Hide overlay when play succeeds (video is playing, even if muted)
            if (playOverlay) {
              playOverlay.classList.remove("visible");
            }
            // Don't unmute automatically - wait for user interaction
            // Unmuting will happen when user clicks on video
            log(
              "‚ÑπÔ∏è Video playing muted - will unmute on user interaction",
              "info"
            );
          })
          .catch((error) => {
            log(
              `‚ö†Ô∏è Video play() (muted) attempt failed: ${error.message}`,
              "warning"
            );
            // If muted play fails, try unmuted
            attemptVideoPlay();
          });
      }

      function attemptVideoPlay() {
        if (!remoteVideo || !remoteVideo.srcObject) return;

        videoPlayAttempts++;
        remoteVideo
          .play()
          .then(() => {
            log("‚úÖ Video play() succeeded", "success");
            videoPlayAttempts = 0; // Reset on success
            isUnmuted = true;
            // Hide overlay when play succeeds
            if (playOverlay) {
              playOverlay.classList.remove("visible");
            }
          })
          .catch((error) => {
            log(
              `‚ö†Ô∏è Video play() attempt ${videoPlayAttempts} failed: ${error.message}`,
              "warning"
            );
            // Retry up to 5 times with increasing delays
            if (videoPlayAttempts < 5) {
              setTimeout(() => {
                if (remoteVideo.paused) {
                  attemptVideoPlay();
                }
              }, 500 * videoPlayAttempts);
            } else {
              log(
                "‚ùå All video play() attempts failed - showing play overlay",
                "error"
              );
              // Show overlay to prompt user to click
              if (playOverlay && remoteVideo.readyState >= 2) {
                playOverlay.classList.add("visible");
              }
            }
          });
      }

      // Monitor video statistics to check if packets are actually arriving
      function startVideoStatisticsMonitoring(track) {
        if (!peerConnection) return;

        const statsInterval = setInterval(async () => {
          if (!peerConnection || peerConnection.connectionState === "closed") {
            clearInterval(statsInterval);
            return;
          }

          try {
            const stats = await peerConnection.getStats();
            let videoBytesReceived = 0;
            let videoPacketsReceived = 0;
            let videoFramesDecoded = 0;
            let videoFramesDropped = 0;

            stats.forEach((report) => {
              if (
                report.type === "inbound-rtp" &&
                report.mediaType === "video"
              ) {
                videoBytesReceived = report.bytesReceived || 0;
                videoPacketsReceived = report.packetsReceived || 0;
                videoFramesDecoded = report.framesDecoded || 0;
                videoFramesDropped = report.framesDropped || 0;
              }
            });

            // Log statistics every 3 seconds
            if (videoBytesReceived > 0) {
              log(
                `üìä [STATS] Video: ${(videoBytesReceived / 1024).toFixed(
                  1
                )} KB received, ` +
                  `${videoPacketsReceived} packets, ${videoFramesDecoded} frames decoded`,
                "info"
              );

              if (videoFramesDropped > 0) {
                log(
                  `‚ö†Ô∏è [STATS] ${videoFramesDropped} frames dropped`,
                  "warning"
                );
              }

              // If we're receiving data but track is muted, there's an issue
              if (track.muted && videoBytesReceived > 0) {
                log(
                  "‚ö†Ô∏è [STATS] Track is muted but receiving data - possible decoder issue",
                  "warning"
                );
                // Try to force play
                attemptVideoPlay();
              }
            } else {
              log(
                "‚ö†Ô∏è [STATS] No video bytes received - broadcast extension may not be sending frames",
                "warning"
              );
            }
          } catch (err) {
            log(`‚ö†Ô∏è [STATS] Error getting stats: ${err.message}`, "warning");
          }
        }, 3000); // Every 3 seconds

        // Clear interval after 30 seconds
        setTimeout(() => {
          clearInterval(statsInterval);
        }, 30000);
      }

      // Set up periodic keyframe requests from receiver
      // Note: Direct RTCP PLI requests may not be available in all browsers
      // The iOS sender should handle periodic keyframe generation
      function setupKeyframeRequests(track) {
        // Request keyframes every 2 seconds to ensure decoder always has recent keyframe
        // This helps recover from packet loss and prevents freezing
        const keyframeInterval = setInterval(() => {
          if (peerConnection && track.readyState === "live") {
            // Request keyframe using RTCP PLI (Picture Loss Indication)
            // This is done by getting the receiver and requesting a keyframe
            const receivers = peerConnection.getReceivers();
            const videoReceiver = receivers.find(
              (r) => r.track && r.track.kind === "video"
            );

            if (videoReceiver) {
              // Request keyframe - this sends RTCP PLI to the sender
              // Note: This may not be directly available in all browsers
              // The sender should handle this via periodic keyframe generation
              log("üîë Requesting keyframe from sender", "info");
            }
          } else {
            clearInterval(keyframeInterval);
          }
        }, 2000); // Every 2 seconds

        log("üîë Keyframe request timer started (every 2 seconds)", "info");

        // Clean up on disconnect
        peerConnection.addEventListener("connectionstatechange", () => {
          if (peerConnection.connectionState === "closed") {
            clearInterval(keyframeInterval);
          }
        });
      }

      let isProcessingOffer = false; // Prevent duplicate offer processing

      function handleSignalingMessage(message) {
        if (!peerConnection) {
          log("‚ö†Ô∏è Peer connection not created yet", "warning");
          return;
        }

        switch (message.type) {
          case "offer":
            // Prevent processing the same offer multiple times
            if (isProcessingOffer) {
              log(
                "‚ö†Ô∏è Offer already being processed, ignoring duplicate",
                "warning"
              );
              return;
            }
            isProcessingOffer = true;
            log("üì• Received offer, creating answer...", "info");
            handleOffer(message).finally(() => {
              // Reset flag after processing completes (success or error)
              setTimeout(() => {
                isProcessingOffer = false;
              }, 1000);
            });
            break;

          case "answer":
            log("üì• Received answer", "info");
            handleAnswer(message);
            break;

          case "candidate":
            log("üì• Received ICE candidate", "info");
            handleIceCandidate(message);
            break;

          default:
            log(`‚ö†Ô∏è Unknown message type: ${message.type}`, "warning");
        }
      }

      async function handleOffer(message) {
        try {
          log("üì• ========== PROCESSING OFFER ==========", "info");
          log("üì• Received offer from iOS device", "info");
          updateStatus("connecting", "Processing offer...");

          if (!message.sdp) {
            log("‚ùå ERROR: Offer message missing SDP!", "error");
            isProcessingOffer = false;
            return;
          }

          log(`üìã SDP Length: ${message.sdp.length} characters`, "info");

          // Check if remote description is already set
          if (peerConnection.remoteDescription) {
            log(
              "‚ö†Ô∏è Remote description already set, skipping duplicate offer",
              "warning"
            );
            isProcessingOffer = false;
            return;
          }

          await peerConnection.setRemoteDescription(
            new RTCSessionDescription({
              type: "offer",
              sdp: message.sdp,
            })
          );
          log("‚úÖ Remote description (offer) set successfully", "success");
          log("üìä Status: Creating answer...", "info");

          // Create answer with constraints to receive video
          const answerConstraints = {
            offerToReceiveAudio: false,
            offerToReceiveVideo: true, // IMPORTANT: Must receive video
          };
          const answer = await peerConnection.createAnswer(answerConstraints);
          log("‚úÖ Answer created successfully", "success");

          // Verify video is in answer SDP
          if (answer.sdp.includes("m=video")) {
            log("‚úÖ Video media line (m=video) found in answer SDP", "success");
          } else {
            log("‚ùå ERROR: Video media line NOT found in answer SDP!", "error");
          }

          // Verify H.264 is used (not VP8/VP9)
          if (answer.sdp.includes("H264") || answer.sdp.includes("h264")) {
            log("‚úÖ H.264 codec found in answer SDP", "success");
          } else {
            log("‚ùå ERROR: H.264 codec NOT found in answer SDP!", "error");
          }

          if (answer.sdp.includes("VP8") || answer.sdp.includes("VP9")) {
            log(
              "‚ö†Ô∏è WARNING: VP8/VP9 found in answer SDP (should be H.264 only)",
              "warning"
            );
          } else {
            log("‚úÖ VP8/VP9 not found in answer SDP (H.264 only)", "success");
          }

          // Check if local description is already set
          if (peerConnection.localDescription) {
            log(
              "‚ö†Ô∏è Local description already set, skipping duplicate setLocalDescription",
              "warning"
            );
          } else {
            await peerConnection.setLocalDescription(answer);
            log("‚úÖ Local description (answer) set successfully", "success");
          }

          log(`üìã Answer SDP Length: ${answer.sdp.length} characters`, "info");

          sendSignalingMessage({
            type: "answer",
            sdp: answer.sdp,
          });
          log("üì§ ========== ANSWER SENT ==========", "success");
          log("üì§ Answer sent to signaling server", "success");
          log("üìä Status: Waiting for ICE candidates...", "info");
        } catch (error) {
          log(`‚ùå ERROR: Failed to handle offer`, "error");
          log(`‚ùå Error: ${error.message}`, "error");
          log(`‚ùå Stack: ${error.stack}`, "error");
          isProcessingOffer = false;
        }
      }

      async function handleAnswer(message) {
        try {
          await peerConnection.setRemoteDescription(
            new RTCSessionDescription({
              type: "answer",
              sdp: message.sdp,
            })
          );
          log("‚úÖ Remote description set (answer)", "success");
        } catch (error) {
          log(`‚ùå Error handling answer: ${error.message}`, "error");
        }
      }

      async function handleIceCandidate(message) {
        try {
          await peerConnection.addIceCandidate(
            new RTCIceCandidate({
              candidate: message.candidate,
              sdpMLineIndex: message.sdpMLineIndex,
              sdpMid: message.sdpMid,
            })
          );
          log("‚úÖ ICE candidate added", "success");
        } catch (error) {
          log(`‚ùå Error adding ICE candidate: ${error.message}`, "error");
        }
      }

      function sendSignalingMessage(message) {
        if (websocket && websocket.readyState === WebSocket.OPEN) {
          const messageStr = JSON.stringify(message);
          websocket.send(messageStr);
          log(`üì§ ========== MESSAGE SENT ==========`, "info");
          log(`üì§ Message Type: ${message.type}`, "info");
          if (message.sdp) {
            log(`üì§ SDP Length: ${message.sdp.length} characters`, "info");
          }
          if (message.candidate) {
            log(`üì§ ICE Candidate sent`, "info");
          }
        } else {
          log("‚ùå ERROR: Cannot send message", "error");
          log(
            `‚ùå WebSocket state: ${websocket ? websocket.readyState : "null"}`,
            "error"
          );
          log(
            `‚ùå Expected: OPEN (1), Current: ${websocket?.readyState}`,
            "error"
          );
        }
      }

      function disconnect() {
        // Full cleanup (used on page unload)
        log("üîå Disconnecting...", "info");

        if (peerConnection) {
          peerConnection.close();
          peerConnection = null;
        }

        if (websocket) {
          websocket.close();
          websocket = null;
        }

        remoteVideo.srcObject = null;
        updateStatus("disconnected", "Disconnected");
        sessionState = "disconnected";
        updateSessionButton();

        log("‚úÖ Disconnected", "success");
      }

      // Whether remote input / commands should be allowed to flow
      // Only when the session is connected AND WebRTC is in a connected state.
      function isRemoteInputAllowed() {
        if (sessionState !== "connected") {
          log(
            `‚ö†Ô∏è Remote input blocked: sessionState=${sessionState} (expected "connected")`,
            "warning"
          );
          return false;
        }
        if (!peerConnection) {
          log("‚ö†Ô∏è Remote input blocked: peerConnection is null", "warning");
          return false;
        }
        const pcState = peerConnection.connectionState;
        if (pcState !== "connected") {
          log(
            `‚ö†Ô∏è Remote input blocked: WebRTC state=${pcState} (expected "connected")`,
            "warning"
          );
          return false;
        }
        return true;
      }

      // ============================
      // Remote control helpers
      // ============================

      /**
       * Send a RemoteMessageEnvelope for input/command/diagnostics
       * over the same WebSocket. The iOS main app will decode these
       * and map them into in-app gestures / commands / diagnostics.
       */
      function sendRemoteEnvelope(envelope) {
        // Guard: only send remote input when the session + WebRTC are connected.
        if (!isRemoteInputAllowed()) {
          updateInputStatus("ignored (not connected)");
          return;
        }
        // Reuse the existing signaling sender for convenience
        sendSignalingMessage(envelope);
      }

      /**
       * Send a remote tap-like gesture.
       */
      function sendRemoteTap(normalizedX, normalizedY) {
        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "tap",
            position: { x: normalizedX, y: normalizedY },
          },
        };
        sendRemoteEnvelope(envelope);
        updateInputStatus(
          `tap @ (${normalizedX.toFixed(3)}, ${normalizedY.toFixed(3)})`
        );
      }

      /**
       * Send a remote double-tap gesture at a normalized coordinate.
       */
      function sendRemoteDoubleTap(normalizedX, normalizedY) {
        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "doubleTap",
            position: { x: normalizedX, y: normalizedY },
          },
        };
        sendRemoteEnvelope(envelope);
        updateInputStatus(
          `doubleTap @ (${normalizedX.toFixed(3)}, ${normalizedY.toFixed(3)})`
        );
      }

      /**
       * Send a remote long-press gesture at a normalized coordinate.
       */
      function sendRemoteLongPress(normalizedX, normalizedY, durationMs) {
        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "longPress",
            position: { x: normalizedX, y: normalizedY },
            durationMs: Math.round(durationMs),
          },
        };
        sendRemoteEnvelope(envelope);
        updateInputStatus(
          `longPress (${Math.round(durationMs)}ms) @ (${normalizedX.toFixed(
            3
          )}, ${normalizedY.toFixed(3)})`
        );
      }

      /**
       * Send a remote swipe gesture between two normalized points.
       */
      function sendRemoteSwipe(startX, startY, endX, endY) {
        const dx = endX - startX;
        const dy = endY - startY;

        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "swipe",
            start: { x: startX, y: startY },
            end: { x: endX, y: endY },
            deltaX: dx,
            deltaY: dy,
          },
        };

        sendRemoteEnvelope(envelope);
        updateInputStatus(
          `swipe Œî(${dx.toFixed(3)}, ${dy.toFixed(3)}) from (${startX.toFixed(
            3
          )}, ${startY.toFixed(3)})`
        );
      }

      /**
       * Send a remote pan / drag gesture between two normalized points.
       */
      function sendRemotePan(startX, startY, endX, endY, durationMs) {
        const dx = endX - startX;
        const dy = endY - startY;

        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "pan",
            start: { x: startX, y: startY },
            end: { x: endX, y: endY },
            deltaX: dx,
            deltaY: dy,
            durationMs: Math.round(durationMs),
          },
        };

        sendRemoteEnvelope(envelope);
        updateInputStatus(
          `pan Œî(${dx.toFixed(3)}, ${dy.toFixed(3)}) from (${startX.toFixed(
            3
          )}, ${startY.toFixed(3)})`
        );
      }

      /**
       * Keyboard helpers
       */
      function sendRemoteKeyboardText(text) {
        if (!text || !text.trim()) return;
        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "keyboardText",
            text: text,
          },
        };
        sendRemoteEnvelope(envelope);
        updateInputStatus(`keyboardText "${text}"`);
      }

      function sendRemoteKeyboardKey(keyCode) {
        const envelope = {
          type: "input",
          sessionId: null,
          input: {
            kind: "keyboardKey",
            keyCode: keyCode,
          },
        };
        sendRemoteEnvelope(envelope);
        updateInputStatus(`keyboardKey ${keyCode}`);
      }

      function sendKeyboardTextFromInput() {
        const kbInput = document.getElementById("kbText");
        if (!kbInput) return;
        const text = kbInput.value;
        sendRemoteKeyboardText(text);
        kbInput.value = "";
      }

      /**
       * Navigation command helpers
       */
      function sendRemoteCommand(type, parameters) {
        const envelope = {
          type: "command",
          sessionId: null,
          command: {
            type: type,
            parameters: parameters || null,
          },
        };
        sendRemoteEnvelope(envelope);
        updateInputStatus(`command ${type}`);
      }

      function sendOpenScreen(screenId) {
        sendRemoteCommand("openScreen", { screen: screenId });
      }

      function sendPopScreen() {
        sendRemoteCommand("popScreen", null);
      }

      function sendPopToRoot() {
        sendRemoteCommand("popToRoot", null);
      }

      // When the support agent clicks on the remote video:
      // - single click ‚Üí tap
      // - double click (within browser's double-click threshold) ‚Üí doubleTap
      // Handle overlay click to enable playback
      if (playOverlay) {
        playOverlay.addEventListener("click", async (event) => {
          event.stopPropagation();
          try {
            await remoteVideo.play();
            log("‚úÖ [VIDEO] Playback enabled by overlay click", "success");
            playOverlay.classList.remove("visible");
          } catch (err) {
            log(
              `‚ö†Ô∏è [VIDEO] play() failed on overlay click: ${err.message}`,
              "warning"
            );
          }
        });
      }

      remoteVideo.addEventListener("click", async (event) => {
        // Enable playback on click if paused (fixes autoplay policy)
        if (remoteVideo.paused) {
          try {
            await remoteVideo.play();
            log("‚úÖ [VIDEO] Playback enabled by user click", "success");
            if (playOverlay) {
              playOverlay.classList.remove("visible");
            }
          } catch (err) {
            log(`‚ö†Ô∏è [VIDEO] play() failed on click: ${err.message}`, "warning");
          }
        }

        // Unmute video on user click (user gesture allows unmuting)
        if (remoteVideo.muted && !remoteVideo.paused) {
          try {
            remoteVideo.muted = false;
            isUnmuted = true;
            log("‚úÖ [VIDEO] Video unmuted by user click", "success");
          } catch (err) {
            log(`‚ö†Ô∏è [VIDEO] Unmute failed: ${err.message}`, "warning");
          }
        }

        try {
          // If we already fired a long-press for this interaction, skip tap.
          if (suppressNextClickFromLongPress) {
            suppressNextClickFromLongPress = false;
            return;
          }

          const rect = remoteVideo.getBoundingClientRect();
          if (!rect.width || !rect.height) {
            return;
          }
          const x = (event.clientX - rect.left) / rect.width;
          const y = (event.clientY - rect.top) / rect.height;

          // If this is the second click of a double-click sequence,
          // treat it as a double tap immediately.
          if (event.detail === 2) {
            if (pendingTapTimeout) {
              clearTimeout(pendingTapTimeout);
              pendingTapTimeout = null;
            }
            log(
              `üéÆ Remote DOUBLE TAP at video coords (${x.toFixed(
                3
              )}, ${y.toFixed(3)})`,
              "info"
            );
            sendRemoteDoubleTap(x, y);
            pendingTapPosition = null;
            return;
          }

          // Otherwise, schedule a single tap, which will be cancelled
          // if a second click arrives (event.detail === 2).
          pendingTapPosition = { x, y };

          if (pendingTapTimeout) {
            clearTimeout(pendingTapTimeout);
          }

          pendingTapTimeout = setTimeout(() => {
            log(
              `üéÆ Remote tap at video coords (${x.toFixed(3)}, ${y.toFixed(
                3
              )})`,
              "info"
            );
            sendRemoteTap(x, y);
            pendingTapTimeout = null;
            pendingTapPosition = null;
          }, 350); // slightly generous window in case of slow double-click
        } catch (e) {
          log(`‚ùå Failed to queue remote tap: ${e.message}`, "error");
        }
      });

      // Mouse press handlers for long-press detection.
      remoteVideo.addEventListener("mousedown", (event) => {
        try {
          const rect = remoteVideo.getBoundingClientRect();
          if (!rect.width || !rect.height) {
            return;
          }
          const x = (event.clientX - rect.left) / rect.width;
          const y = (event.clientY - rect.top) / rect.height;

          longPressStartTime = Date.now();
          longPressPosition = { x, y };
          swipeStartTime = longPressStartTime;
          swipeStartPosition = { x, y };

          // Start timer; if it fires, we treat as a long-press.
          longPressTimer = setTimeout(() => {
            if (!longPressStartTime || !longPressPosition) {
              return;
            }
            const duration = Date.now() - longPressStartTime;
            log(
              `üéÆ Remote LONG PRESS at video coords (${x.toFixed(
                3
              )}, ${y.toFixed(3)}) for ${duration}ms`,
              "info"
            );
            sendRemoteLongPress(x, y, duration);

            // Prevent the subsequent click from sending a tap.
            suppressNextClickFromLongPress = true;

            longPressTimer = null;
          }, 600); // 600ms press threshold
        } catch (e) {
          log(`‚ùå Failed to start long-press detection: ${e.message}`, "error");
        }
      });

      function cancelLongPressIfNeeded() {
        if (longPressTimer) {
          clearTimeout(longPressTimer);
          longPressTimer = null;
        }
        longPressStartTime = null;
        longPressPosition = null;
      }

      function maybeSendSwipe(event) {
        try {
          if (!swipeStartTime || !swipeStartPosition) {
            return;
          }

          const rect = remoteVideo.getBoundingClientRect();
          if (!rect.width || !rect.height) {
            return;
          }

          const endX = (event.clientX - rect.left) / rect.width;
          const endY = (event.clientY - rect.top) / rect.height;

          const dx = endX - swipeStartPosition.x;
          const dy = endY - swipeStartPosition.y;
          const distance = Math.sqrt(dx * dx + dy * dy);
          const duration = Date.now() - swipeStartTime;

          // Thresholds: distinguish fast long gestures (swipe) from slower drags (pan)
          const minSwipeDistance = 0.08; // ~8% of view
          const minPanDistance = 0.03; // smaller threshold for pan
          const maxSwipeDuration = 600; // ms (same ballpark as long-press threshold)

          if (distance >= minSwipeDistance && duration <= maxSwipeDuration) {
            log(
              `üéÆ Remote SWIPE from (${swipeStartPosition.x.toFixed(
                3
              )}, ${swipeStartPosition.y.toFixed(3)}) to (${endX.toFixed(
                3
              )}, ${endY.toFixed(3)})`,
              "info"
            );
            sendRemoteSwipe(
              swipeStartPosition.x,
              swipeStartPosition.y,
              endX,
              endY
            );
            // Prevent the subsequent click from sending a tap.
            suppressNextClickFromLongPress = true;
          } else if (distance >= minPanDistance) {
            log(
              `üéÆ Remote PAN from (${swipeStartPosition.x.toFixed(
                3
              )}, ${swipeStartPosition.y.toFixed(3)}) to (${endX.toFixed(
                3
              )}, ${endY.toFixed(3)})`,
              "info"
            );
            sendRemotePan(
              swipeStartPosition.x,
              swipeStartPosition.y,
              endX,
              endY,
              duration
            );
            suppressNextClickFromLongPress = true;
          }
        } catch (e) {
          log(`‚ùå Failed to send swipe/pan: ${e.message}`, "error");
        } finally {
          swipeStartTime = null;
          swipeStartPosition = null;
        }
      }

      remoteVideo.addEventListener("mouseup", (event) => {
        maybeSendSwipe(event);
        cancelLongPressIfNeeded();
      });

      remoteVideo.addEventListener("mouseleave", () => {
        cancelLongPressIfNeeded();
      });

      // Keyboard input: submit on Enter (without Shift).
      const kbInputEl = document.getElementById("kbText");
      if (kbInputEl) {
        kbInputEl.addEventListener("keydown", (event) => {
          if (event.key === "Enter" && !event.shiftKey) {
            event.preventDefault();
            sendKeyboardTextFromInput();
          }
        });
      }

      // Cleanup on page unload
      window.addEventListener("beforeunload", () => {
        disconnect();
      });

      // Initial log
      sessionState = "disconnected";
      updateSessionButton();

      // CRITICAL: Prime autoplay permission immediately on page load
      // This establishes user gesture context for autoplay (browsers allow this)
      // We start muted because browsers allow muted autoplay more easily
      if (remoteVideo) {
        remoteVideo.muted = true; // Start muted for easier autoplay
        remoteVideo.play().catch((err) => {
          // This will fail, but it primes the autoplay permission
          log(
            "üîì [AUTOPLAY] Priming autoplay permission (expected to fail initially)",
            "info"
          );
        });
      }

      // Check if roomId is in URL and auto-connect
      const urlParams = new URLSearchParams(window.location.search);
      const urlRoomId =
        urlParams.get("room")?.trim() || urlParams.get("roomId")?.trim();

      if (urlRoomId) {
        log(
          `üöÄ Web client ready. RoomId detected: ${urlRoomId}. Auto-connecting...`,
          "info"
        );
        // Small delay to ensure DOM is fully ready
        setTimeout(() => {
          startSession();
        }, 100);
      } else {
        log("üöÄ Web client ready. Click Start Session to begin.", "info");
      }
    </script>
  </body>
</html>
